### Emulating a compiler ---> based on the compilation mountain

def tokenizer(command_string) -> list:
    '''
    lexer ---> lexicographic split of the command passed in
    returns tokens based on each line of text instruction
    '''
    tokens = []
    tokens = command_string.split()
    return tokens

def parser(tokens):
    '''
    create an AST from the tokens generated by the lexer/tokenizer
    '''
    


print(tokenizer("var x = 100 + 100"))
